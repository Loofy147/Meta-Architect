from dataclasses import dataclass
from typing import List
from lma.cmcg import CrossModalCausalGraph
from lma.telemetry import TelemetrySnapshot


@dataclass
class Hypothesis:
    """Represents a causal hypothesis generated by the HGE.

    This dataclass provides a structured format for storing hypotheses about
    the model's behavior, including the proposed causal link, the evidence
    supporting it, and a prediction that can be used to test it.

    Attributes:
        id (str): A unique identifier for the hypothesis.
        description (str): A human-readable summary of the hypothesis.
        antecedent (str): The cause or condition part of the hypothesis.
        consequent (str): The expected effect or outcome.
        confidence (float): A numerical value (0.0 to 1.0) representing the
            confidence in the hypothesis.
        supporting_evidence (List[str]): A list of metric values or observations
            that support the hypothesis.
        testable_prediction (str): A specific, falsifiable prediction that can
            be used to validate the hypothesis.
    """

    id: str
    description: str
    antecedent: str  # Condition
    consequent: str  # Expected effect
    confidence: float
    supporting_evidence: List[str]
    testable_prediction: str


class HypothesisGenerationEngine:
    """Generates causal hypotheses from telemetry patterns.

    The Hypothesis Generation Engine (HGE) is responsible for analyzing
    telemetry data and identifying patterns that suggest potential causal
    relationships within the model. It uses a set of predefined patterns to
    create `Hypothesis` objects, which can then be used for further reasoning
    or intervention.

    Attributes:
        cmcg (CrossModalCausalGraph): A reference to the causal graph, used to
            inform hypothesis generation.
        hypothesis_counter (int): A counter for generating unique hypothesis IDs.
        active_hypotheses (List[Hypothesis]): A list of currently active
            hypotheses.
    """

    def __init__(self, cmcg: CrossModalCausalGraph):
        """Initializes the HypothesisGenerationEngine.

        Args:
            cmcg (CrossModalCausalGraph): The causal graph to be used for context.
        """
        self.cmcg = cmcg
        self.hypothesis_counter = 0
        self.active_hypotheses: List[Hypothesis] = []

    def generate_from_snapshot(self, snapshot: TelemetrySnapshot) -> List[Hypothesis]:
        """Generates a list of hypotheses based on the data in a telemetry snapshot.

        This method applies a set of predefined pattern detectors to the snapshot
        data. When a pattern is matched, a corresponding `Hypothesis` object is
        created and added to the list of active hypotheses.

        Args:
            snapshot (TelemetrySnapshot): The telemetry data for the current
                timestep.

        Returns:
            List[Hypothesis]: A list of newly generated hypotheses.
        """
        hypotheses = []

        # Pattern 1: High kappa + Low gradient → Rank collapse causing vanishing gradient
        for key, kappa in snapshot.condition_numbers.items():
            if kappa > 50:
                coord = key.split("_")[0]
                grad = snapshot.gradient_norms.get(coord, 1.0)
                if grad < 1e-4:
                    h = Hypothesis(
                        id=f"H-{self.hypothesis_counter}",
                        description="Rank collapse causing vanishing gradient",
                        antecedent=f"κ({key}) > 50 AND ||∇|| < 1e-4",
                        consequent="Vanishing gradient in affected head",
                        confidence=0.85,
                        supporting_evidence=[f"κ={kappa:.2f}", f"||∇||={grad:.2e}"],
                        testable_prediction="Reset projections will restore gradient flow",
                    )
                    hypotheses.append(h)
                    self.hypothesis_counter += 1

        # Pattern 2: Entropy decline + T_mix increase → Specialization-complexity coupling
        for coord, entropy in snapshot.attention_entropy.items():
            deriv = snapshot.entropy_derivatives.get(coord, 0)
            if deriv < -0.01 and snapshot.t_mix > 45:
                h = Hypothesis(
                    id=f"H-{self.hypothesis_counter}",
                    description="Entropy decline driving GNN complexity",
                    antecedent=f"ΔH({coord})/Δt < -0.01 AND T_mix > 45µs",
                    consequent="Increased mixing computational load",
                    confidence=0.73,
                    supporting_evidence=[
                        f"H={entropy:.3f}",
                        f"ΔH={deriv:.4f}",
                        f"T_mix={snapshot.t_mix:.1f}µs",
                    ],
                    testable_prediction="Entropy regularization will reduce T_mix",
                )
                hypotheses.append(h)
                self.hypothesis_counter += 1

        self.active_hypotheses.extend(hypotheses)
        return hypotheses
